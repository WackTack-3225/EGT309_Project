# Min Zheng - Flask app

# Define the Namespace
apiVersion: v1
kind: Namespace # abstraction layer to prevent pods from being build in base env to prevent accidental errors
metadata:
  name: ml-app

---

apiVersion: v1
kind: ConfigMap # useful tool to allow easier access & modification of URL/File paths 
metadata:
  name: flask-url
  namespace: ml-app
data:
  DP_POD_URL: "http://processing-service:84/start-processing" # WORKING
  MODEL_TRAINING_URL: "http://model-training-service:85/train" # SET TO CORRECT (?)
  RESULTS_URL: "http://model-training-service:85/results" # SET TO CORRECT(?)
  INF_POD_URL: "http://inference-service:83/predict" # WORKING

---
# Flask App Deployment
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-app
  namespace: ml-app
spec:
  replicas: 3 # MAX 3 containers deployed
  selector:
    matchLabels:
      chapter: flask # Applies configuration to containers w/ label flask
  strategy:
    type: RollingUpdate # Deploy/Remove/Update pods based on specs below
    rollingUpdate:
      maxUnavailable: 1 # max 1 pod unavail at a time
      maxSurge: 1 # max 1 extra pod avail at a time
  template:
    metadata:
      labels:
        chapter: flask # create from a temaplate (image) and apply label flask for svc to connect
    spec:
      containers:
      - name: flask-container
        image: wacktack/flask-app:latest # pull from flask-app image
        env: # to get Config map variables
        - name: DP_POD_URL
          valueFrom:
            configMapKeyRef:
              name: flask-url
              key: DP_POD_URL
        - name: MODEL_TRAINING_URL
          valueFrom:
            configMapKeyRef:
              name: flask-url
              key: MODEL_TRAINING_URL
        - name: RESULTS_URL
          valueFrom:
            configMapKeyRef:
              name: flask-url
              key: RESULTS_URL
        - name: INF_POD_URL
          valueFrom:
            configMapKeyRef:
              name: flask-url
              key: INF_POD_URL
        ports:
        - containerPort: 5000 # set port 5000, same as app.py

---
# Flask app service
apiVersion: v1
kind: Service
metadata:
  name: flask-app-service
  namespace: ml-app # deploy in same namespace to access
  labels:
    chapter: flask # unique calling method to ensure service operates on this specific chapter
spec:
  type: NodePort  # LoadBalancer for external
  ports:
  - protocol: TCP
    port: 5000  # Exposed port
    targetPort: 5000  # Flask app port inside the container
  selector:
    chapter: flask # applies to selected chapter: flask

---
# Inference Container - Edyson
# Configmap

# Store non-confidential data

apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: ml-app        # The namespace in which the Service is created
data:
  DATA_PATH: "/mnt/data"
  MODEL_PATH: "/mnt/save-model"
  VOLUME_MOUNT_PATH: "/mnt"


---

# Service

# Service accessible from within the cluster (ClusterIP) and will sent traffic to pods
# it manages (recieves on 80 sent to containers at 8083)
# Does not deploy or manage pods just route traffic
# If can control >1 pod it will auto route traffic to them

apiVersion: v1  # Specifies the API version to use for the Service object
kind: Service   # Defines this as a Service object
metadata:
  name: inference-service  # The name of the Service
  namespace: ml-app        # The namespace in which the Service is created
spec:
  selector:
    app: inference         # Labels used to identify the pods this Service targets
  ports:
  - protocol: TCP          # The protocol for the port (usually TCP)
    port: 83               # The port that the Service exposes to the outside world
    targetPort: 8083       # The port on the pod/container that the Service forwards traffic to
  type: ClusterIP          # The type of Service; ClusterIP means it's accessible only within the cluster

---

# PVC

# To allow request of a storage, request 4 Gi

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: store-model-pvc
  namespace: ml-app        # The namespace in which the PVC is created
spec:
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 4Gi

---

# Inference Deployment

# Deployment use template to how pod shld be created
# Replicaset controller created from deployment and it ensure pod is at desired state
# and will mintor and if not it delete, create and manage pods
# Note: rollback history is gone (no history of replicasets) if deployment.yaml is deleted and reapplied, only has history if its reapplied without deleting and only has history if changes is in template

apiVersion: apps/v1 
kind: Deployment   
metadata:
  name: inference    # Name of Deployment
  namespace: ml-app  # The namespace in which the Deployment is created
spec:
  replicas: 3        # Number of pod replicas that should be running at all times
  revisionHistoryLimit: 8  # Retain the last 8 ReplicaSets for rollback (decreased from default) ensuring enough versions are kept for rollback without bloating
  minReadySeconds: 15 # Giving 15 seconds buffer time for pod to stabilize after being ready before being able to recieve traffic (Means pod marked as ready need state read for 15 seconds before being considered available to recieve traffic)
  # It in turns tells kubernetes that replica needs to run for 10 seconds before update/replace of next one in sequence
  progressDeadlineSeconds: 600  # 10 minutes to complete the update or considered as failed
  selector:
    matchLabels:
      app: inference # Label Deployment uses to manage the pods it creates
  strategy:
    type: RollingUpdate  # Deployment strategy; RollingUpdate updates the pods in a rolling fashion
    rollingUpdate:
      maxUnavailable: 1  # During an update, at most 1 pod can be unavailable at a time
      maxSurge: 1        # During an update, at most 1 extra pod can be created temporarily
      # Matching maxunavailale and maxsurge ensures stradyrollout with no reduction in total available pods
  template:
    metadata:
      name: inference-pod
      labels:
        app: inference   # Labels attached to the pods created by this Deployment
    spec:
      restartPolicy: Always #Wont restart for 1 time task
      containers:
        - name: inference-container
          image: edysontan/inference
          ports:
            - containerPort: 8083        # Port that the container listens on
          volumeMounts:
            - mountPath: /mnt  # Path inside container colume mounted at
              name: store-model-volume
          env: # environment variables for container to use
            - name: DATA_PATH
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: DATA_PATH
            - name: MODEL_PATH
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: MODEL_PATH
            - name: VOLUME_MOUNT_PATH
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: VOLUME_MOUNT_PATH
      volumes: # Associate store-model-volume to store-model-pvc and volumemount mounts this associated volume to /mnt
        - name: store-model-volume
          persistentVolumeClaim:
            claimName: store-model-pvc
---
### Hai jie
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-training-deployment
  namespace: ml-app
spec:
  replicas: 1  # Number of pod replicas
  selector:
    matchLabels:
      app: model-training
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    metadata:
      labels:
        app: model-training
    spec:
      containers:
      - name: model-training # model training code
        image: 200iqkid/modeltrain # hai jie's image
        volumeMounts:
        - mountPath: "/app/data"  # to modify
          name: processed-data-pv
        - mountPath: '/mnt/saved_model'  # to modify
          name: saved-model-volume

      volumes:
      - name: processed-data-pv # jurn jie's volume claim
        persistentVolumeClaim:
          claimName: processed-data-pvc
      - name: saved-model-volume # hai jie'svolume claim
        persistentVolumeClaim:
          claimName: saved-model-pvc

---
# PV for saved model
apiVersion: v1
kind: PersistentVolume
metadata:
  name: saved-model-pv  # Name of the Persistent Volume for the saved model
  namespace: ml-app
spec:
  capacity:
    storage: 4Gi  
  accessModes:
    - ReadWriteMany  
  hostPath:
    path: "/mnt/saved_model"  # Path on the host machine where the model will be saved
  persistentVolumeReclaimPolicy: Retain


---
# PVC for saved model
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: saved-model-pvc  # Name of the PVC that will request the saved model volume
  namespace: ml-app  
spec:
  accessModes:
    - ReadWriteOnce  
  resources:
    requests:
      storage: 4Gi  

---
apiVersion: v1 
kind: Service 
metadata:
  name: model-training-service  
  namespace: ml-app
spec:
  selector:
    app: model-training         # Labels used to identify the pods this Service targets
  ports:
  - protocol: TCP          # The protocol for the port (usually TCP)
    port: 85               # The port that the Service exposes to the outside world
    targetPort: 8085       # The port on the pod/container that the Service forwards traffic to
  type: ClusterIP          # The type of Service; ClusterIP means it's accessible only within the cluster

---
### Jurn Jie
# Service

apiVersion: v1
kind: Service
metadata:
  name: processing-service
  namespace: ml-app
spec:
  selector:
    app: data-processing
  ports:
  - protocol: TCP
    port: 84
    targetPort: 8084
  type: ClusterIP

---

# PV
# allow request of storage

apiVersion: v1
kind: PersistentVolume
metadata:
  name: processed-data-pv
spec:
  capacity:
    storage: 4Gi
  accessModes:
    - ReadWriteMany
  hostPath:
    path: "/mnt/data"
---

# PVC 

apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: processed-data-pvc
  namespace: ml-app
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 4Gi

---

# Deployment 
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-processing-deployment
  namespace: ml-app
  labels:
    app: data-processing
spec:
  replicas: 3
  selector:
    matchLabels:
      app: data-processing
  template:
    metadata:
      labels:
        app: data-processing
    spec:
      containers:
      - name: data-processing-container
        image: 200iqkid/data-processing:latest
        volumeMounts:
        - mountPath: "/app/processed_data"
          name: processed-data-pv
        env:
        - name: TRAIN_DIR
          value: "/app/data_309/train"
        - name: TEST_DIR
          value: "/app/data_309/test"
      # Connecting PVC to PV
      volumes:
      - name: processed-data-pv
        persistentVolumeClaim:
          claimName: processed-data-pvc
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  revisionHistoryLimit: 10  # Keep a history of 10 revisions for rollback
  minReadySeconds: 5  # Minimum time a Pod should be ready before considered stable
  progressDeadlineSeconds: 600  # Deadline for progressing the deployment   