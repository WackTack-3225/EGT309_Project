# Note: for the documentation of deployment files, please inspect the individual deploy.yml/deployment.yml/deployment.yaml files found within each individual's sections

# Namespace
apiVersion: v1
kind: Namespace
metadata:
  name: ml-app
---
# Config Mapping

apiVersion: v1
kind: ConfigMap
metadata:
  name: app-config
  namespace: ml-app
data:
  # used by min zheng - flask
  DP_POD_URL: "http://processing-service:84/start-processing" 
  MODEL_TRAINING_URL: "http://model-training-service:82/train" 
  RESULT_URL: "http://model-training-service:82/results" 
  INF_POD_URL: "http://inference-service:83/predict" 

  # used by edyson - model saved location
  MODEL_PATH: "/mnt/saved_model"

  # used by hai jie - model saved location
  MODEL_SAVE_PATH: "/mnt/saved_model"

---
# Service (1/4) - Flask App(Min Zheng)
apiVersion: v1
kind: Service
metadata:
  name: flask-app-service
  namespace: ml-app 
  labels:
    chapter: flask 
spec:
  type: NodePort
  ports:
  - protocol: TCP
    port: 5000  
    targetPort: 5000 
    nodePort: 30005
  selector:
    chapter: flask
---
# Service (2/4) - Flask App(Jurn Jie)
apiVersion: v1
kind: Service
metadata:
  name: processing-service
  namespace: ml-app
spec:
  selector:
    app: data-processing
  ports:
  - protocol: TCP
    port: 84
    targetPort: 8084
  type: ClusterIP
---
# Service (3/4) - Flask App(Hai Jie)
apiVersion: v1 
kind: Service 
metadata:
  name: model-training-service  
  namespace: ml-app
spec:
  selector:
    app: model-training
  ports:
  - protocol: TCP      
    port: 82         
    targetPort: 8082    
  type: ClusterIP   

---
# Service (4/4) - Flask App(Edyson)
apiVersion: v1  
kind: Service  
metadata:
  name: inference-service 
  namespace: ml-app     
spec:
  selector:
    app: inference      
  ports:
  - protocol: TCP       
    port: 83          
    targetPort: 8083   
  type: ClusterIP

---
# Persistent Volumes (1/2) - Jurn Jie
apiVersion: v1
kind: PersistentVolume
metadata:
  name: processed-data-pv
spec:
  capacity:
    storage: 4Gi
  accessModes:
    - ReadWriteMany
  hostPath:
    path: "/mnt/data"

---
# Persistent Volumes (2/2) - Hai Jie
apiVersion: v1
kind: PersistentVolume
metadata:
  name: saved-model-volume
  namespace: ml-app
spec:
  capacity:
    storage: 4Gi  
  accessModes:
    - ReadWriteMany  
  hostPath:
    path: "/mnt/saved_model"  
  persistentVolumeReclaimPolicy: Retain

---
# Persistent Volume Claims (1/2) - Jurn Jie
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: processed-data-pvc
  namespace: ml-app
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 4Gi

---
# Persistent Volume Claims (2/2) - Hai Jie
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: saved-model-pvc
  namespace: ml-app  
spec:
  accessModes:
    - ReadWriteOnce  
  resources:
    requests:
      storage: 4Gi  

---
# Deployment (1/4) - Min Zheng
apiVersion: apps/v1
kind: Deployment
metadata:
  name: flask-app
  namespace: ml-app
spec:
  replicas: 3
  selector:
    matchLabels:
      chapter: flask 
  strategy:
    type: RollingUpdate 
    rollingUpdate:
      maxUnavailable: 1 
      maxSurge: 1 
  template:
    metadata:
      labels:
        chapter: flask 
    spec:
      containers:
      - name: flask-container 
        image:  wacktack/flask-app:final-build
        env:
        - name: DP_POD_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: DP_POD_URL
        - name: MODEL_TRAINING_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: MODEL_TRAINING_URL
        - name: RESULT_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: RESULT_URL
        - name: INF_POD_URL
          valueFrom:
            configMapKeyRef:
              name: app-config
              key: INF_POD_URL
        ports:
        - containerPort: 5000 # set port 5000, same as app.py

---
# Deployment (2/4) - Jurn Jie
apiVersion: apps/v1
kind: Deployment
metadata:
  name: data-processing-deployment
  namespace: ml-app
  labels:
    app: data-processing
spec:
  replicas: 3
  selector:
    matchLabels:
      app: data-processing
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 1
  revisionHistoryLimit: 10 
  minReadySeconds: 5  
  progressDeadlineSeconds: 600  
  template:
    metadata:
      labels:
        app: data-processing
    spec:
      containers:
      - name: data-processing-container
        image: jurnjie/data-processing:final-build
        volumeMounts:
        - name: processed-data-pv 
          mountPath: "/app/processed_data"
        env:
        - name: TRAIN_DIR
          value: "/app/data_309/train"
        - name: TEST_DIR
          value: "/app/data_309/test"
      volumes:
      - name: processed-data-pv
        persistentVolumeClaim:
          claimName: processed-data-pvc

---
# Deployment (3/4) - Hai Jie
apiVersion: apps/v1
kind: Deployment
metadata:
  name: model-training-deployment
  namespace: ml-app
spec:
  replicas: 3
  selector:
    matchLabels:
      app: model-training
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  template:
    metadata:
      labels:
        app: model-training
    spec:
      containers:
      - name: model-training
        image: edysontan/model-training:latest
        volumeMounts:
        - name: processed-data-pv
          mountPath: "/app/data"
        - name: saved-model-volume
          mountPath: '/mnt/saved_model'
      volumes:
      - name: processed-data-pv
        persistentVolumeClaim:
          claimName: processed-data-pvc
      - name: saved-model-volume
        persistentVolumeClaim:
          claimName: saved-model-pvc

---
# Deployment (4/4) - Edyson
apiVersion: apps/v1 
kind: Deployment   
metadata:
  name: inference-deployment
  namespace: ml-app 
spec:
  replicas: 3 
  selector:
    matchLabels:
      app: inference
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 1
      maxSurge: 1
  revisionHistoryLimit: 8 
  minReadySeconds: 15
  progressDeadlineSeconds: 600
  template:
    metadata:
      name: inference-pod
      labels:
        app: inference
    spec:
      restartPolicy: Always
      containers:
        - name: inference-container
          image: edysontan/inference:final-build
          ports:
            - containerPort: 8083
          volumeMounts:
            - name: saved-model-volume
              mountPath: /mnt/saved_model
          env:
            - name: MODEL_PATH
              valueFrom:
                configMapKeyRef:
                  name: app-config
                  key: MODEL_PATH
      volumes: 
        - name: saved-model-volume
          persistentVolumeClaim:
            claimName: saved-model-pvc